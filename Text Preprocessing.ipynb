{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e848f91d-19fe-44fc-8823-47d4d07135a3",
   "metadata": {},
   "source": [
    "# Text Preprocessing in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b432b141-bc0e-4df4-8a37-62f6fc1fa96b",
   "metadata": {},
   "source": [
    "## Text Preprocessing Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949b085b-709a-4b60-a57b-50811b388acc",
   "metadata": {},
   "source": [
    "Importing the required libraries and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dcf3c96-5704-4a35-b640-0f87409bc2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #importing pandas\n",
    "import numpy as np #importing numpy\n",
    "import seaborn as sns #importing seaborn\n",
    "import matplotlib.pyplot as plt #importing matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d6ad06e-e88c-4483-be7e-bcb387e96491",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(\"K:\\DATA SCIENCE\\DataSets\\IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a382e41-7f08-4cd2-98c9-5671cb3a2b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92213fd9-7879-430a-839f-8ac648286f36",
   "metadata": {},
   "source": [
    "### 1) Lower Casing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c005a7-f566-4f8b-a850-abad10622f70",
   "metadata": {},
   "source": [
    "* What is Lower Casing?\n",
    "  Converting the text into lowercase is called as lower casing. \"What\" will be converted into \"what\".\n",
    "\n",
    "* Why it is done?\n",
    "  * Reduces Vocabulary Size:Imagine the words \"The\" and \"the\" being treated as different words by an NLP model. This would effectively double the number of words the model needs to consider, making it more complex and potentially less accurate. Lowercasing forces \"The\" and \"the\" to be considered the same word, reducing the vocabulary size and simplifying the model's task.\n",
    "  * Improves Model Consistency: Capitalization can vary depending on the context. For instance, \"US\" and \"U.S.\" could represent the same thing. Lowercasing eliminates these inconsistencies, allowing the model to focus on the core meaning of the word rather than capitalization variations. This can lead to more consistent and accurate results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db36f5b-b9b5-442e-9519-03da80175be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['review'] = movies['review'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc501134-2e21-44e8-ae4c-d3f9b1946f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. &lt;br /&gt;&lt;br /&gt;the...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. <br /><br />the...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4743d71e-d317-4a3b-a531-614d485d0843",
   "metadata": {},
   "source": [
    "### 2) Removing HTML tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ae624-f4c8-49e2-bd6b-f2f937fb76a2",
   "metadata": {},
   "source": [
    "* In Natural Language Processing (NLP), removing HTML tags refers to the process of cleaning text data by eliminating the code used for formatting and presentation on web pages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb19e69-9080-4607-a871-d275d0094fec",
   "metadata": {},
   "source": [
    "* This is done for a few key reasons:\n",
    "\n",
    " \n",
    "    *  Focus on Content, Not Presentation: NLP tasks like sentiment analysis or topic modeling aim to understand the meaning conveyed by the text. HTML tags don't contribute to the core meaning and can even introduce noise. Removing them allows the NLP model to concentrate on the actual content of the text.\n",
    "    *  Simplify Text Processing:  HTML tags can add complexity to the text data.  For instance, nested tags or complex structures can make it difficult for NLP algorithms to parse and analyze the text efficiently. Removing these tags creates a cleaner and more structured format, streamlining the processing pipeline.\n",
    "    *  Standardization:  Websites can use different HTML tags and formatting styles.  By removing these variations, you create a standardized format for the text data. This consistency makes it easier to train and apply NLP models across different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d751d15e-5ae4-47f3-b47c-06e03d23c984",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66cc5b46-5371-4eaa-b90e-2a01cccc8bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7faa6002-9b9f-4a79-9af5-3097bf5b01ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['review'] = movies['review'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0016fb08-6c21-4b3b-9419-50d88073989c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production. the filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei's \"love in the time of money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production. the filming tec...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically there's a family where a little boy ...  negative\n",
       "4  petter mattei's \"love in the time of money\" is...  positive"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8135dcae-4988-4ba2-a689-cf1f33033343",
   "metadata": {},
   "source": [
    "### 3) Removing URLs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5fec96-89df-41ce-a149-bb72c8078a3f",
   "metadata": {},
   "source": [
    "* In NLP, removing URLs refers to the process of eliminating website addresses and hyperlinks from text data.\n",
    "\n",
    "\n",
    "\n",
    "* This is done for a couple of reasons:This is done for a couple of reasons:\n",
    "    *  Focus on Content, Not References: NLP tasks often aim to understand the meaning and sentiment of text. URLs themselves don't contribute much to this meaning. By removing them, the NLP model can concentrate on the core content of the text, like the surrounding words and their relationships\n",
    " \n",
    "    *  Reduce Noise and Improve Efficiency:  URLs can introduce unnecessary noise into the data. They can vary greatly in length and format, making it harder for the model to learn patterns. Removing them simplifies the data and can improve the efficiency and accuracy of the NLP process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b69ce04-b372-4d6a-918b-68864ff0fe36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mario lewis of the competitive enterprise institute has written a definitive 120-page point-by-point, line-by-line refutation of this mendacious film, which should be titled a convenient lie. the website address where his debunking report, which is titled \"a skeptic\\'s guide to an inconvenient truth\" can be found at is :www.cei.org. a shorter 10-page version can be found at: www.cei.org/pdf/5539.pdf once you read those demolitions, you\\'ll realize that alleged \"global warming\" is no more real or dangerous than the y2k scare of 1999, which gore also endorsed, as he did the pseudo-scientific film the day after tomorrow, which was based on a book written by alleged ufo abductee whitley strieber. as james \"the amazing\" randi does to psychics, and philip klass does to ufos, and gerald posner does to jfk conspir-idiocy theories, so does mario lewis does to al gore\\'s movie and the whole \"global warming\" scam.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['review'].iloc[742]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f05d1a8b-00a2-43f6-b0bc-c71591572ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def remove_url(text):\n",
    "    pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return pattern.sub(r'',text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "594016c3-0e40-4160-bcf9-284faad30c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['review'] = movies['review'].apply(remove_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70e06e00-6005-4506-a118-95d72baba624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mario lewis of the competitive enterprise institute has written a definitive 120-page point-by-point, line-by-line refutation of this mendacious film, which should be titled a convenient lie. the website address where his debunking report, which is titled \"a skeptic\\'s guide to an inconvenient truth\" can be found at is : a shorter 10-page version can be found at:  once you read those demolitions, you\\'ll realize that alleged \"global warming\" is no more real or dangerous than the y2k scare of 1999, which gore also endorsed, as he did the pseudo-scientific film the day after tomorrow, which was based on a book written by alleged ufo abductee whitley strieber. as james \"the amazing\" randi does to psychics, and philip klass does to ufos, and gerald posner does to jfk conspir-idiocy theories, so does mario lewis does to al gore\\'s movie and the whole \"global warming\" scam.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['review'].iloc[742]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe3dd4b-c5b9-4877-85d6-4079dfedfbd1",
   "metadata": {},
   "source": [
    "### 4) Removing Punctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cd522b-8338-490a-adea-35bf651e5d62",
   "metadata": {},
   "source": [
    "* In NLP, removing punctuation refers to the process of eliminating punctuation marks from text data.\n",
    "\n",
    "\n",
    "* This is a common text pre-processing step done for a few reasons\n",
    "    \n",
    "    \n",
    "    *  Focusing on Word Meaning: Punctuation primarily conveys emphasis, tone, and grammatical structure. In many NLP tasks, we're more interested in the core meaning conveyed by the words themselves. Removing punctuation allows the model to concentrate on the semantic content of the text, treating words like \"data\" and \"data!\" identically.\n",
    "    *  Reducing Vocabulary Size: Similar to lowercasing, removing punctuation helps shrink the vocabulary size an NLP model needs to handle. Punctuation variations like commas, periods, and exclamation marks wouldn't be considered separate \"words\" by the model, streamlining the processing.\n",
    "    *  Standardizing Text: Punctuation usage can vary depending on writing style or origin. Removing it ensures consistency in the text data presented to the model. This can be particularly helpful when dealing with large datasets from diverse sources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a237c5c0-bef6-4d40-8b6e-9f0b15eca510",
   "metadata": {},
   "source": [
    "* However, removing punctuation isn't always advisable. Here's when it might not be the best approach:\n",
    "\n",
    "    * Sentiment Analysis: Punctuation can be crucial for understanding sentiment. An exclamation mark can drastically change the meaning of a sentence compared to a period.\n",
    "    * Sarcasm Detection: Sarcasm often relies on punctuation like quotation marks or italics, which wouldn't be captured if removed.\n",
    "    * Emojis: Emojis are a form of punctuation that convey emotions. Removing them would eliminate valuable information, especially in informal communication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a65c6e92-425a-45cf-bc34-3e13a810895e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "exclude = string.punctuation\n",
    "\n",
    "def remove_punc(text):\n",
    "    return text.translate(str.maketrans('','',exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2093f59b-26a9-4362-9e5f-0a6b9f2f8f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['review'] = movies['review'].apply(remove_punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efa0b888-087a-4500-98b6-4006b67945f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production the filming tech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres a family where a little boy j...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love in the time of money is a ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one of the other reviewers has mentioned that ...  positive\n",
       "1  a wonderful little production the filming tech...  positive\n",
       "2  i thought this was a wonderful way to spend ti...  positive\n",
       "3  basically theres a family where a little boy j...  negative\n",
       "4  petter matteis love in the time of money is a ...  positive"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a5a073-6c99-4312-b6fd-6a7237214f56",
   "metadata": {},
   "source": [
    "### 5) Spelling Corrections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ff8c4f-5f49-4b96-a07c-2d8ecb35b9f6",
   "metadata": {},
   "source": [
    "* Spelling correction in NLP is the process of identifying and fixing errors in written text. This is crucial for several reasons:\n",
    "\n",
    "    * Improved Accuracy: Many NLP tasks rely on understanding the meaning of text. Misspelled words can confuse the model and lead to inaccurate results. By correcting spelling errors, NLP applications can function with greater accuracy.\n",
    "    *  Handling Informal Text: Informal communication, like social media posts or emails, often contains typos and slang. Spelling correction helps NLP models understand these informal styles of writing and extract meaning from them.\n",
    "    *  Data Cleaning: Large amounts of text data used in NLP tasks may contain typos due to various reasons like optical character recognition (OCR) errors or user mistakes. Spelling correction helps clean this data and prepare it for better NLP processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4c56ac8-d438-4d9f-9528-8b02e68e32c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79d752e0-c8a1-45a8-addc-986550565960",
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_text = ' Hell how are you fiine'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "626bca9e-a06b-4361-8f59-8c569ddc7965",
   "metadata": {},
   "outputs": [],
   "source": [
    "textblb = TextBlob(incorrect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd739ba2-b6b9-462e-868c-5943f1360ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Well how are you fine'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textblb.correct().string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8bc2d8-e471-44f6-89c3-c0590e5124cc",
   "metadata": {},
   "source": [
    "### 6) Removing Stop Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35cce2d-70ab-4bd9-a405-b28d2861a16d",
   "metadata": {},
   "source": [
    "* In Natural Language Processing (NLP), removing stop words is a technique used during text pre-processing. Stop words are very common words that carry little meaning on their own. Examples include \"the\", \"a\", \"is\", \"in\", \"of\", etc.\r\n",
    "* \r\n",
    "Here's why removing stop words is commonly don\n",
    "\n",
    "    * Focus on Content: Stop words don't contribute much to the actual content or meaning of a sentence. By removing them, NLP models can focus on the more important words that convey the core ideas. This can be particularly beneficial for tasks like sentiment analysis or topic modeling.\n",
    "    * Reduce Noise: Stop words can be seen as noise in the data. Removing them reduces the overall data size and makes it easier for NLP models to learn patterns and relationships between the important words. This can lead to improved model performance.\n",
    "    * Improve Efficiency: Since there are fewer words to process, removing stop words can make NLP tasks more efficient, especially when dealing with large datasets.e:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cf1a5e6-e7ee-4a3f-9bd8-1111029a3e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44d0b1d1-6001-4bf2-8a4f-7a2b625bb7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21286c0b-0c17-4238-a7d9-d86742b3862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slower but easier to understand Method\n",
    "def remove_stopWords(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if word in stopwords.words('english'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    x = new_text[:]\n",
    "    new_text.clear()\n",
    "    return '' ''.join(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b3f8e4b-aa4a-4b2d-b7e4-d5cd2a429794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster Method\n",
    "def remove_stopWords1(text):\n",
    "    stop_words = set(stopwords.words('english'))  # Convert stopwords to a set for faster lookup\n",
    "    return ' '.join(word for word in text.split() if word not in stop_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15044df4-e62c-466a-84f3-4babfb7f698f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "movies['review'] = movies['review'].apply(remove_stopWords1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd1378c8-e57b-41a3-8d4b-f0ccf364eb00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one reviewers mentioned watching 1 oz episode ...  positive\n",
       "1  wonderful little production filming technique ...  positive\n",
       "2  thought wonderful way spend time hot summer we...  positive\n",
       "3  basically theres family little boy jake thinks...  negative\n",
       "4  petter matteis love time money visually stunni...  positive"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b98dd4c-281a-47e1-a787-87ec3bbc3d38",
   "metadata": {},
   "source": [
    "### 7) Handling Emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b636cc-5315-44ab-941f-04abba9950e0",
   "metadata": {},
   "source": [
    "* Removing emojis in NLP refers to the process of filtering out emoji characters from text data during preprocessing. Here's a breakdown of why this is done:\n",
    "\n",
    "    * Focus on Core Meaning: Emojis are often visual representations of emotions or ideas. In tasks like sentiment analysis or topic modeling, the focus is on the underlying meaning conveyed by words. Removing emojis helps the NLP model concentrate on the core textual content.\n",
    "    * Data Consistency: Emojis can have subjective interpretations. A happy face emoji might indicate joy for one person and sarcasm for another. Removing them ensures consistency in the data the model analyzes.\n",
    "    * Reduced Complexity: Emojis can add complexity, especially for simpler models. By removing them, the model deals with a smaller set of characters, potentially improving processing efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07935a17-2c7d-45ba-b7ba-74d390638d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_emoji(text):\n",
    "  emoji_pattern = re.compile(\"[\"\n",
    "    u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "    u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "    u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "    u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "    u\"\\U00002702-\\U000027B0\"  # dingbats\n",
    "    u\"\\U000024C2-\\U0001F251\"  # variation selectors\n",
    "     \"]+\", flags=re.UNICODE)\n",
    "  return emoji_pattern.sub(r'', text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "821f1f08-6f0b-40dd-85d7-965021844788",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['review'] = movies['review'].apply(remove_emoji)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2fab09-0420-4537-9282-034afd4e1faf",
   "metadata": {},
   "source": [
    "our data didn't had any emojis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9404a184-07f8-4bd4-a6a2-e0b3705ac4c7",
   "metadata": {},
   "source": [
    "### 8) Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458e4c1e-b792-4c96-ad99-935bd94248d2",
   "metadata": {},
   "source": [
    "* Tokenization in NLP refers to the process of breaking down a piece of text into smaller units called tokens. These tokens can be individual words, characters, or even phrases, depending on the specific task and chosen approach. It's essentially the foundation of any NLP pipeline, prepping the text data for further analysis.wer of NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b597ec-9862-433e-a1d7-d44730047dbb",
   "metadata": {},
   "source": [
    "* There are a couple of key reasons why tokenization is crucial in NLP:\n",
    "\n",
    "    * Makes Text Manageable for Machines: Raw text is a continuous stream of characters for computers. Tokenization chops it up into discrete units that machines can understand and process more easily. Imagine trying to analyze the meaning of a whole paragraph at once – it's overwhelming! Tokens provide bite-sized pieces for efficient analysis.\n",
    "\n",
    "    * Enables Further NLP Tasks:  Tokenization acts like a springboard for various NLP applications. By having the text separated into tokens, you can perform tasks like:\n",
    "\n",
    "    * Identifying Parts of Speech: Recognizing nouns, verbs, adjectives, etc. in the tokens helps understand the sentence structure and meaning.\n",
    "    * Building Vocabularies: Creating a list of unique tokens from a text corpus helps NLP models understand the language and identify patterns.\n",
    "\n",
    "    * Performing Text Cleaning: Removing punctuation, stop words (common words like \"the\" or \"and\" with little meaning) and other irrelevant elements often happens after tokenization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5290d0-109c-43aa-acb0-511ce9681c31",
   "metadata": {},
   "source": [
    "In essence, tokenization transforms unstructured text data into a structured format that computers can work with, making it the essential first step in unlocking the power of NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b38c2444-b86c-4cf6-b0f6-86b3bdafbb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3a2606b-9b61-4fd0-9b28-dc9bf3cc2ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\siddh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfbae53-35c0-4979-b9f4-960d7d199878",
   "metadata": {},
   "source": [
    "a) Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bca6d471-1b1f-4341-8b1e-7cae1723b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_words(text):\n",
    "  return nltk.word_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b789dc9-b28f-4ad2-a6a0-c552ba18dded",
   "metadata": {},
   "source": [
    "b) Sentence Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0eb5e821-a0cc-47f6-9c7b-1b5e3c1c76ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentences(text):\n",
    "  return nltk.sent_tokenize(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0108ee44-68e8-4cd3-955a-41e415ab585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['review_word_token'] = movies['review'].apply(tokenize_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "153fd405-477c-46a8-9027-8b76d3c9aa19",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['review_sent_token'] = movies['review'].apply(tokenize_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4f2cda26-6722-4ebb-bf6a-9712544da02d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_word_token</th>\n",
       "      <th>review_sent_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, reviewers, mentioned, watching, 1, oz, e...</td>\n",
       "      <td>[one reviewers mentioned watching 1 oz episode...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "      <td>[wonderful little production filming technique...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought wonderful way spend time hot summer w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basically, theres, family, little, boy, jake,...</td>\n",
       "      <td>[basically theres family little boy jake think...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "      <td>[petter matteis love time money visually stunn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  one reviewers mentioned watching 1 oz episode ...  positive   \n",
       "1  wonderful little production filming technique ...  positive   \n",
       "2  thought wonderful way spend time hot summer we...  positive   \n",
       "3  basically theres family little boy jake thinks...  negative   \n",
       "4  petter matteis love time money visually stunni...  positive   \n",
       "\n",
       "                                   review_word_token  \\\n",
       "0  [one, reviewers, mentioned, watching, 1, oz, e...   \n",
       "1  [wonderful, little, production, filming, techn...   \n",
       "2  [thought, wonderful, way, spend, time, hot, su...   \n",
       "3  [basically, theres, family, little, boy, jake,...   \n",
       "4  [petter, matteis, love, time, money, visually,...   \n",
       "\n",
       "                                   review_sent_token  \n",
       "0  [one reviewers mentioned watching 1 oz episode...  \n",
       "1  [wonderful little production filming technique...  \n",
       "2  [thought wonderful way spend time hot summer w...  \n",
       "3  [basically theres family little boy jake think...  \n",
       "4  [petter matteis love time money visually stunn...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b491c-1105-4404-908a-1293d0ca5d86",
   "metadata": {},
   "source": [
    "### 9) Stemming & Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb816a0e-18fa-4e5a-8ab3-53ce22495094",
   "metadata": {},
   "source": [
    "* Stemming in NLP refers to the process of reducing words to their base or root form. This is done by chopping off prefixes and suffixes from words, aiming to get to a more generalizable form."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1aa2aeb-740d-4c2d-9bf7-995ad80c2dab",
   "metadata": {},
   "source": [
    "* Here's why stemming is done in NLP:\n",
    "\n",
    "    * Reduces Redundancy: Words with different endings (like \"playing\", \"played\", \"plays\") often convey the same core meaning. Stemming reduces these variations to a single \"play\", streamlining the text for processing.\n",
    "\n",
    "    * Improves Efficiency: By reducing word variants, stemming helps manage the vocabulary size an NLP system needs to handle. This makes the system more efficient, especially when dealing with large amounts of text data.\n",
    "\n",
    "    * Enhances Text Matching: Stemming allows for better matching between words in a query and words in a document. Even if the exact word form isn't present, stemming can connect them based on their root meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cccc241-baf4-45e9-b716-a8a7d3167024",
   "metadata": {},
   "source": [
    "* However, it's important to remember that stemming can be a bit rough. Unlike lemmatization (which considers proper grammatical forms), stemming might sometimes create unrecognizable words (\"play\" from \"playing\" is a valid word, but \"teach\" from \"teacher\" is not).iency."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e9f31-f43e-4267-8ba9-39d52747020f",
   "metadata": {},
   "source": [
    "* Here's a quick comparison:\n",
    "    * Stemming: Simpler, faster, may create non-words\n",
    "    * Lemmatization: More accurate, slower, preserves actual words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c59e459-1421-4ed2-a242-36facebf7789",
   "metadata": {},
   "source": [
    "a) PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b6f77c7b-bcd8-4729-8b1d-5d6cd04496f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b2d55ead-b57d-47ec-96c5-49c7672d3486",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8eafe68f-7168-4ffb-93ac-e317eb968d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_words(text):\n",
    "    return \" \".join([ps.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f2c8f49-53fc-4e21-bf89-1dcc2ea06a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['review_stemming'] = movies['review'].apply(stem_words) # you can apply stemming on tokenized data also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ed99277d-a149-434e-a249-17ba52cd1218",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_word_token</th>\n",
       "      <th>review_sent_token</th>\n",
       "      <th>review_stemming</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, reviewers, mentioned, watching, 1, oz, e...</td>\n",
       "      <td>[one reviewers mentioned watching 1 oz episode...</td>\n",
       "      <td>one review mention watch 1 oz episod youll hoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "      <td>[wonderful little production filming technique...</td>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought wonderful way spend time hot summer w...</td>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basically, theres, family, little, boy, jake,...</td>\n",
       "      <td>[basically theres family little boy jake think...</td>\n",
       "      <td>basic there famili littl boy jake think there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "      <td>[petter matteis love time money visually stunn...</td>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  one reviewers mentioned watching 1 oz episode ...  positive   \n",
       "1  wonderful little production filming technique ...  positive   \n",
       "2  thought wonderful way spend time hot summer we...  positive   \n",
       "3  basically theres family little boy jake thinks...  negative   \n",
       "4  petter matteis love time money visually stunni...  positive   \n",
       "\n",
       "                                   review_word_token  \\\n",
       "0  [one, reviewers, mentioned, watching, 1, oz, e...   \n",
       "1  [wonderful, little, production, filming, techn...   \n",
       "2  [thought, wonderful, way, spend, time, hot, su...   \n",
       "3  [basically, theres, family, little, boy, jake,...   \n",
       "4  [petter, matteis, love, time, money, visually,...   \n",
       "\n",
       "                                   review_sent_token  \\\n",
       "0  [one reviewers mentioned watching 1 oz episode...   \n",
       "1  [wonderful little production filming technique...   \n",
       "2  [thought wonderful way spend time hot summer w...   \n",
       "3  [basically theres family little boy jake think...   \n",
       "4  [petter matteis love time money visually stunn...   \n",
       "\n",
       "                                     review_stemming  \n",
       "0  one review mention watch 1 oz episod youll hoo...  \n",
       "1  wonder littl product film techniqu unassum old...  \n",
       "2  thought wonder way spend time hot summer weeke...  \n",
       "3  basic there famili littl boy jake think there ...  \n",
       "4  petter mattei love time money visual stun film...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbb165-1d7c-4210-806b-9df7783749f4",
   "metadata": {},
   "source": [
    "b) Lemmitization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ce6f76bf-198e-4505-94ea-80a62c5efdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dec0ca8f-e88d-468f-a461-f762d8523ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\siddh\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea6f633d-49df-4fab-97b1-ee1bef5f2986",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\siddh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ad1c1292-55d2-4a6f-80dd-8096fd616264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "w_tokenizer = nltk.tokenize.WhitespaceTokenizer()\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    return [lemmatizer.lemmatize(w) for w in w_tokenizer.tokenize(text)]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "386b91ca-e5c7-4133-80e3-9eb179c3b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies['review_Lemmatization'] = movies['review'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ccc7f0f3-9635-4e5c-8bc4-f8c25cca81f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review_word_token</th>\n",
       "      <th>review_sent_token</th>\n",
       "      <th>review_stemming</th>\n",
       "      <th>review_Lemmatization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one reviewers mentioned watching 1 oz episode ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[one, reviewers, mentioned, watching, 1, oz, e...</td>\n",
       "      <td>[one reviewers mentioned watching 1 oz episode...</td>\n",
       "      <td>one review mention watch 1 oz episod youll hoo...</td>\n",
       "      <td>[one, reviewer, mentioned, watching, 1, oz, ep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonderful little production filming technique ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "      <td>[wonderful little production filming technique...</td>\n",
       "      <td>wonder littl product film techniqu unassum old...</td>\n",
       "      <td>[wonderful, little, production, filming, techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "      <td>[thought wonderful way spend time hot summer w...</td>\n",
       "      <td>thought wonder way spend time hot summer weeke...</td>\n",
       "      <td>[thought, wonderful, way, spend, time, hot, su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>negative</td>\n",
       "      <td>[basically, theres, family, little, boy, jake,...</td>\n",
       "      <td>[basically theres family little boy jake think...</td>\n",
       "      <td>basic there famili littl boy jake think there ...</td>\n",
       "      <td>[basically, there, family, little, boy, jake, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>positive</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "      <td>[petter matteis love time money visually stunn...</td>\n",
       "      <td>petter mattei love time money visual stun film...</td>\n",
       "      <td>[petter, matteis, love, time, money, visually,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  one reviewers mentioned watching 1 oz episode ...  positive   \n",
       "1  wonderful little production filming technique ...  positive   \n",
       "2  thought wonderful way spend time hot summer we...  positive   \n",
       "3  basically theres family little boy jake thinks...  negative   \n",
       "4  petter matteis love time money visually stunni...  positive   \n",
       "\n",
       "                                   review_word_token  \\\n",
       "0  [one, reviewers, mentioned, watching, 1, oz, e...   \n",
       "1  [wonderful, little, production, filming, techn...   \n",
       "2  [thought, wonderful, way, spend, time, hot, su...   \n",
       "3  [basically, theres, family, little, boy, jake,...   \n",
       "4  [petter, matteis, love, time, money, visually,...   \n",
       "\n",
       "                                   review_sent_token  \\\n",
       "0  [one reviewers mentioned watching 1 oz episode...   \n",
       "1  [wonderful little production filming technique...   \n",
       "2  [thought wonderful way spend time hot summer w...   \n",
       "3  [basically theres family little boy jake think...   \n",
       "4  [petter matteis love time money visually stunn...   \n",
       "\n",
       "                                     review_stemming  \\\n",
       "0  one review mention watch 1 oz episod youll hoo...   \n",
       "1  wonder littl product film techniqu unassum old...   \n",
       "2  thought wonder way spend time hot summer weeke...   \n",
       "3  basic there famili littl boy jake think there ...   \n",
       "4  petter mattei love time money visual stun film...   \n",
       "\n",
       "                                review_Lemmatization  \n",
       "0  [one, reviewer, mentioned, watching, 1, oz, ep...  \n",
       "1  [wonderful, little, production, filming, techn...  \n",
       "2  [thought, wonderful, way, spend, time, hot, su...  \n",
       "3  [basically, there, family, little, boy, jake, ...  \n",
       "4  [petter, matteis, love, time, money, visually,...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8783be-9770-4bbf-bf46-7fce04094c1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
